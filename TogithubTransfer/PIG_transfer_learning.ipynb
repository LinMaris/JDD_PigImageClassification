{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks 基于Kera的迁移学习实现 (从udacity复制来的源码)\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we use transfer learning to train a CNN to classify pigs.\n",
    "\n",
    "### 1. Load Pig Dataset\n",
    "\n",
    "Before running the code cell below, download the dataset of pig images and place it in the respository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入运行库\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 我的电脑内存设置有问题所以必须运行这行，根据情况自行选择\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    pig_files = np.array(data['filenames'])\n",
    "    pig_targets = np_utils.to_categorical(np.array(data['target']), 30)\n",
    "    return pig_files, pig_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('pigImages/train2')\n",
    "valid_files, valid_targets = load_dataset('pigImages/valid')\n",
    "test_files, test_targets = load_dataset('E:\\DeepLearning\\PigRecog\\Pig_Identification_Qualification_Test_A/')\n",
    "\n",
    "# load ordered list of dog names\n",
    "pig_names = [item[25:-1] for item in glob('pigImages/train2/*/')]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total pig categories.' % len(pig_names))\n",
    "print('There are %s total pig images.\\n' % str(len(train_files) + len(valid_files) + len(test_files)))\n",
    "print('There are %d training pig images.' % len(train_files))\n",
    "print('There are %d validation pig images.' % len(valid_files))\n",
    "print('There are %d test pig images.'% len(test_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 导入Training Images 同时保存dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  用来生成bottleneck feature文件，占用大量内存，如已有文件可以不运行。\n",
    "from keras.applications.vgg16 import VGG16 #VGG16 xception\n",
    "### 设置model\n",
    "model = VGG16(include_top=False, weights='imagenet')\n",
    "### \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 训练集图像生成器 #TransferLearn/pigImages/train\"\n",
    "generator1 = datagen.flow_from_directory(\n",
    "        \"E:/DeepLearning/PigRecog/TransferLearn/pigImages/train2\", # 请自行修改文件所在目录\n",
    "        target_size=(256,144),\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle=False) \n",
    "#　验证集图像生成器\n",
    "generator2 = datagen.flow_from_directory(\n",
    "        \"E:/DeepLearning/PigRecog/TransferLearn/pigImages/valid\",# 请自行修改文件所在目录\n",
    "        target_size=(256, 144),\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "#（2）灌入pre-model的权重\n",
    "model.load_weights(\"C:/Users/Administrator/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "#（3）得到bottleneck feature\n",
    "bottleneck_features_train = model.predict_generator(generator1, 500)\n",
    "# 核心，steps是生成器要返回数据的轮数，每个epoch含有500张图片，与model.fit(samples_per_epoch)相对\n",
    "np.save(open('bottleneck_features_train2V.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "bottleneck_features_validation = model.predict_generator(generator2, 100)\n",
    "# 与model.fit(nb_val_samples)相对，一个epoch有800张图片，验证集\n",
    "np.save(open('bottleneck_features_validationV.npy', 'wb'), bottleneck_features_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###  保存testset数据\n",
    "from keras.applications.xception import Xception #VGG16\n",
    "### 设置model\n",
    "model = Xception(include_top=False, weights='imagenet')\n",
    "### \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "### 生成test集\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#　测试集图像生成器\n",
    "generator3 = datagen.flow_from_directory(\n",
    "        \"E:\\DeepLearning\\PigRecog\\Pig_Identification_Qualification_Test_A/\",# 请自行修改文件所在目录\n",
    "        target_size=(256, 256),\n",
    "        batch_size=16,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "#（2）灌入pre-model的权重\n",
    "model.load_weights(\"C:/Users/Administrator/.keras/models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "#（3）得到bottleneck feature\n",
    "bottleneck_features_validation = model.predict_generator(generator3, 100)\n",
    "# 与model.fit(nb_val_samples)相对，一个epoch有800张图片，测试集\n",
    "np.save(open('bottleneck_features_testX.npy', 'wb'), bottleneck_features_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obtain the Pre-trained Model Bottleneck Features 下载在tf下训练好的模型\n",
    "Before running the code cell below, download the pretrained npz file and place it in the `bottleneck_features/` folder. 参考github上 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bottleneck_features = np.load('E:/DeepLearning/PigRecog/TransferLearn/bottleneck_features_train.npy') # 请自行修改npy文件名， 需要重新训练bottleneck_feastures并保存好\n",
    "train_vgg16 = np.load(open('E:/DeepLearning/PigRecog/TransferLearn/bottleneck_features_train2V.npy','rb'))\n",
    "valid_vgg16 = np.load(open('E:/DeepLearning/PigRecog/TransferLearn/bottleneck_features_validationV.npy','rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 定义网络结构，检查网络模型\n",
    "先用 from keras.layers import 命令导入需要用到的网络模型，再用 model.add 命令叠加网络。 \n",
    "具体操作可参考keras文档：https://keras.io/getting-started/sequential-model-guide/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16 #Xception #VGG16\n",
    "### 设置model\n",
    "model = VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D,Dropout\n",
    "from keras import regularizers,initializers\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Dropout(0.7, input_shape=(8, 8, 2048)))\n",
    "model.add(Conv2D(1024,(3, 3),padding='same',activation='relu', input_shape=(8, 4, 512)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(GlobalAveragePooling2D(input_shape=(8, 8, 512)))   # initializers.random_normal(stddev=0.01)\n",
    "model.add(Conv2D(2048, (3, 3),padding='same', activation='relu',kernel_initializer=initializers.glorot_normal(seed=None)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(120, (5, 5),padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.7))\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.01),kernel_initializer=initializers.glorot_normal(seed=None)\n",
    "               ))# activity_regularizer=regularizers.l1(0.01),\n",
    "model.add(Dense(256, activation='relu',kernel_initializer=initializers.glorot_normal(seed=None)))\n",
    "#model.add(Dropout(0.7))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compile the Model 组装模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', # sgd   Adadelta RMSprop\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train the Model 训练模型，自动存档，下次自动从上次训练保存处开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='Vgg16.weights.best.hdf5', verbose=1, #Xcp\n",
    "                               save_best_only=True)\n",
    "model.fit(train_vgg16, train_targets, epochs=1000,validation_data=(valid_vgg16, valid_targets), \n",
    "          callbacks=[checkpointer], verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Load the Model with the Best Validation Accuracy 读取存储好的最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取测试集\n",
    "test_vgg16 = np.load(open('E:/DeepLearning/PigRecog/TransferLearn/bottleneck_features_testX.npy','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('Xcp.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Calculate Classification Accuracy on Test Set 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "\n",
    "#vgg16_predictions = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) \n",
    "#                     for feature in test_vgg16]\n",
    "\n",
    "# report test accuracy\n",
    "#test_accuracy = 100*np.sum(np.array(vgg16_predictions)==\n",
    "#                           np.argmax(test_targets, axis=1))/len(vgg16_predictions)\n",
    "#print('\\nTest accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "pig_predictions = model.predict_proba(test_vgg16)\n",
    "\n",
    "print( pig_predictions.shape)\n",
    "np.savetxt('pig_pred2.csv', pig_predictions, delimiter = ',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
